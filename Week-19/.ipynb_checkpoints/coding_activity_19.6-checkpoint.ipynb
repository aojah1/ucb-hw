{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `Surprise`\n",
    "\n",
    "This activity focuses on using the `Surprise` library to predict user ratings.  You will use a dataset derived from the movie lense data -- a common benchmark for recommendation algorithms.  Using `Surprise` you will load the data, create a train set and test set, make predictions for a test set, and cross validate the model on the dataset. \n",
    "\n",
    "### Index\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The data is derived from the MovieLens data [here](https://grouplens.org/datasets/movielens/).  A smaller sample has been culled so the processing is faster, but the data is user reviews of different movies.  We have information on the user, movie, and the associated ratings when they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = pd.read_csv('data/movie_ratings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>7</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>17</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title  userId  rating\n",
       "0        1  Toy Story (1995)       1     4.0\n",
       "1        1  Toy Story (1995)       5     4.0\n",
       "2        1  Toy Story (1995)       7     4.5\n",
       "3        1  Toy Story (1995)      15     2.5\n",
       "4        1  Toy Story (1995)      17     4.5"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Loading a Dataset\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the `Reader` and `Dataset` objects to create a dataset object named `sf` below.  Use the dataset to construct a train set named `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'surprise.dataset.DatasetAutoFolds'>\n",
      "<class 'surprise.trainset.Trainset'>\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "reader = ''\n",
    "sf = ''\n",
    "train = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "a = movie_ratings[['userId', 'title', 'rating']]\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "sf = Dataset.load_from_df(a, reader)\n",
    "train = sf.build_full_trainset()\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(sf))\n",
    "print(type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "a_ = movie_ratings[['userId', 'title', 'rating']]\n",
    "reader_ = Reader(rating_scale=(0, 5))\n",
    "sf_ = Dataset.load_from_df(a_, reader_)\n",
    "train_ = sf_.build_full_trainset()\n",
    "#\n",
    "#\n",
    "#\n",
    "assert train.all_items() == train_.all_items()\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Instantiate the `SVD` model\n",
    "\n",
    "Below, create an `SVD` object with 2 factors and assign it as `model` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "model = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model = SVD(n_factors = 2)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model.n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "a_ = movie_ratings[['userId', 'title', 'rating']]\n",
    "reader_ = Reader(rating_scale=(0, 5))\n",
    "sf_ = Dataset.load_from_df(a_, reader_)\n",
    "train_ = sf_.build_full_trainset()\n",
    "model_ = SVD(n_factors = 2)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert train.all_items() == train_.all_items()\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "### Fitting the Model\n",
    "\n",
    "Below, fit the model on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.prediction_algorithms.matrix_factorization.SVD object at 0x7fbdbd8ef890>\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    " #fit your model below\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model.fit(train)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "a_ = movie_ratings[['userId', 'title', 'rating']]\n",
    "reader_ = Reader(rating_scale=(0, 5))\n",
    "sf_ = Dataset.load_from_df(a_, reader_)\n",
    "train_ = sf_.build_full_trainset()\n",
    "model_ = SVD(n_factors = 2)\n",
    "model_.fit(train_)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(model) == type(model_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "### Making Predictions\n",
    "\n",
    "Build a testset named `test` and use this to create a list of predictions for the testset.  Assign this to `predictions_list` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid=1, iid='Toy Story (1995)', r_ui=4.0, est=4.72221554408827, details={'was_impossible': False}), Prediction(uid=1, iid='Grumpier Old Men (1995)', r_ui=4.0, est=4.0275581894141315, details={'was_impossible': False}), Prediction(uid=1, iid='Heat (1995)', r_ui=4.0, est=4.751626561965673, details={'was_impossible': False}), Prediction(uid=1, iid='Seven (a.k.a. Se7en) (1995)', r_ui=5.0, est=4.868344141268149, details={'was_impossible': False}), Prediction(uid=1, iid='Usual Suspects, The (1995)', r_ui=5.0, est=5, details={'was_impossible': False})]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "test = ''\n",
    "predictions_list = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "test = train.build_testset()\n",
    "predictions_list = model.test(test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(predictions_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "test_ = train_.build_testset()\n",
    "predictions_list_ = model_.test(test_)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(predictions_list[0]) == type(predictions_list_[0])\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Cross Validate the Model\n",
    "\n",
    "You may use the test data to evaluate the model, but we can also cross validate the model using the data object `sf`.  Use `RMSE` to cross validate with 5 folds and your results and assign these to `cross_val_results` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_rmse': array([0.87244772, 0.87385015, 0.86235689, 0.8717439 , 0.86558502]), 'fit_time': (0.8716928958892822, 0.8981771469116211, 0.9042961597442627, 0.8981382846832275, 0.9012491703033447), 'test_time': (0.27602505683898926, 0.08134293556213379, 0.08190298080444336, 0.0822598934173584, 0.0808858871459961)}\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "cross_val_results = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "cross_val_results = cross_validate(model, sf, measures=['RMSE'])\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(cross_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "cross_val_results_ = cross_validate(model, sf, measures=['RMSE'])\n",
    "#\n",
    "#\n",
    "#\n",
    "assert cross_val_results.keys() == cross_val_results_.keys()\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
