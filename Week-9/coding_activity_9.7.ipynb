{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9885b323facdad84",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 9.7: Ridge vs. Sequential Feature Selection\n",
    "\n",
    "**Expected Time: 60 Minutes**\n",
    "\n",
    "**Total Points: 40**\n",
    "\n",
    "This activity focuses on comparing the results of a `Ridge` regression model with that of a `LinearRegression` model built using `SequentialFeatureSelector`.  Both of these approaches seek to limit the complexity of the model.  The `Ridge` estimator applies a penalty that shrinks the coefficients of the model while using the `SequentialFeatureSelector` selects a subset of features to build a model with.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-686ed521942cdb92",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bc685dda5c83376a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d817f3e9eedd72c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Insurance Data\n",
    "\n",
    "For this example, we return to the insurance data with cubic features.  Below the train and test data is loaded and the train and test sets are determined.  Recall that the target feature has the logarithm applied to it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ba405bd2b8a324e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_cubic.csv')\n",
    "test = pd.read_csv('data/test_cubic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1be0f946b6eaeed",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['target_log'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_log\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_log\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_log\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m), test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_log\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['target_log'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X_train, y_train = train.drop('target_log', axis = 1), train['target_log']\n",
    "X_test, y_test = test.drop('target_log', axis = 1), test['target_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0efeb53332a708a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 1\n",
    "\n",
    "#### Feature Selection Pipeline\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "- Define a dictionary `param_dict` with key `selector__n_features_to_select` and key `[2, 3, 4, 5]`.\n",
    "- Use `GridSearchCV` construct a grid search over the `n_features_to_select` parameter of the `selector_pipe ` estimator dfined below. Assign your resul to `selector_grid`.\n",
    "- Use the `predict` function on `selector_grid` to compute the predictions on `X_train`. Assign your result to `train_preds`.\n",
    "- Use the `predict` function on `selector_grid` to compute the predictions on `X_test`. Assign your result to `test_preds`.\n",
    "- Use the `mean_squared_error` function to compute the MSE between `y_train` and `train_preds`. Assign your result to `selector_train_mse`.\n",
    "- Use the `mean_squared_error` function to compute the MSE between `y_test` and `test_preds`. Assign your result to `selector_test_mse`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-805d087beeeb8b3b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 {color: black;background-color: white;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 pre{padding: 0;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-toggleable {background-color: white;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-item {z-index: 1;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-parallel-item:only-child::after {width: 0;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-19c722b8-8432-4d6e-bacd-34a2aaf68ff2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                 SequentialFeatureSelector(estimator=LinearRegression())),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4d154c74-142f-4bbc-9503-3065dcbec290\" type=\"checkbox\" ><label for=\"4d154c74-142f-4bbc-9503-3065dcbec290\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;selector&#x27;,\n",
       "                 SequentialFeatureSelector(estimator=LinearRegression())),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6061cdc5-3942-4d79-b684-0bc327036563\" type=\"checkbox\" ><label for=\"6061cdc5-3942-4d79-b684-0bc327036563\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">selector: SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(estimator=LinearRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bc62fbc5-590e-4edb-b2b6-9f2db82b7f32\" type=\"checkbox\" ><label for=\"bc62fbc5-590e-4edb-b2b6-9f2db82b7f32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2bdd9a14-e58c-4173-a9aa-efe7488fe6ce\" type=\"checkbox\" ><label for=\"2bdd9a14-e58c-4173-a9aa-efe7488fe6ce\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('selector',\n",
       "                 SequentialFeatureSelector(estimator=LinearRegression())),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_pipe = Pipeline([('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                         ('model', LinearRegression())])\n",
    "selector_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f580fcbb41258cf9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.6031734290034885\n",
      "Test MSE: 0.5655875591380699\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "\n",
    "\n",
    "param_dict = {}\n",
    "selector_grid = ''\n",
    "selector_train_mse = ''\n",
    "selector_test_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "param_dict = {'selector__n_features_to_select': [2, 3, 4, 5]}\n",
    "selector_grid = GridSearchCV(selector_pipe, param_grid=param_dict)\n",
    "selector_grid.fit(X_train, y_train)\n",
    "train_preds = selector_grid.predict(X_train)\n",
    "test_preds = selector_grid.predict(X_test)\n",
    "selector_train_mse = mean_squared_error(y_train, train_preds)\n",
    "selector_test_mse = mean_squared_error(y_test, test_preds)\n",
    "### END SOLUTION\n",
    "\n",
    "# ANSWER CHECK\n",
    "print(f'Train MSE: {selector_train_mse}')\n",
    "print(f'Test MSE: {selector_test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b991b67a5ac0214d",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "selector_pipe_ = Pipeline([('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                         ('model', LinearRegression())])\n",
    "param_dict_ = {'selector__n_features_to_select': [2, 3, 4, 5]}\n",
    "selector_grid_ = GridSearchCV(selector_pipe_, param_grid=param_dict_)\n",
    "selector_grid_.fit(X_train, y_train)\n",
    "train_preds_ = selector_grid_.predict(X_train)\n",
    "test_preds_ = selector_grid_.predict(X_test)\n",
    "selector_train_mse_ = mean_squared_error(y_train, train_preds_)\n",
    "selector_test_mse_ = mean_squared_error(y_test, test_preds_)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert list(param_dict_.values()) == list(param_dict.values()), 'Check the parameter dictionary -- double underscores after selector'\n",
    "assert selector_train_mse == selector_train_mse_\n",
    "assert selector_test_mse == selector_test_mse_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-882a2f7363bd17d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Ridge Grid\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "- Define a parameter dictionary named `ridge_param_dict` for the grid search. For this, use `np.logspace(0, 10, 50)` to create a range of alpha values `ridge__alpha`. This function generates values evenly spaced in logarithmic scale from 1 to 10^10. The parameter dictionary is specified as follows: `ridge_param_dict = {'ridge__alpha': np.logspace(0, 10, 50)}`.\n",
    "- Next, construct a `Pipeline` that contains two steps -- `scaler` and `ridge` that first standard scales the data and then build a ridge regression model.  Assign your pipeline as `ridge_pipe`.  Use this to execute the grid search over the `alpha` hyperparameter of the `Ridge` estimator using the training data. Determine the mean squared error on the train and test data. \n",
    "- Use `GridSearchCV` construct a grid search over the `ridge_param_dict` parameter of the `ridge_pipe ` estimator dfined below. Assign your resul to `ridge_grid`.\n",
    "- Use the `predict` function on `ridge_grid` to compute the predictions on `X_train`. Assign your result to `ridge_train_preds`.\n",
    "- Use the `predict` function on `ridge_grid` to compute the predictions on `X_test`. Assign your result to `ridge_test_preds`.\n",
    "- Use the `mean_squared_error` function to compute the MSE between `y_train` and `train_preds`. Assign your result to `ridge_train_mse`.\n",
    "- Use the `mean_squared_error` function to compute the MSE between `y_test` and `test_preds`. Assign your result to `ridge_test_mse`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b21362896fb19ee9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.5870277750390882\n",
      "Test MSE: 0.5532169282339894\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 {color: black;background-color: white;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 pre{padding: 0;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-toggleable {background-color: white;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-estimator:hover {background-color: #d4ebff;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-item {z-index: 1;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-parallel-item:only-child::after {width: 0;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-ebb0ab12-96bb-4f54-9b1c-454344123783 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-ebb0ab12-96bb-4f54-9b1c-454344123783\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;ridge&#x27;, Ridge())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6ca95dc5-8423-47e1-a0cb-7c60a34dcf6c\" type=\"checkbox\" ><label for=\"6ca95dc5-8423-47e1-a0cb-7c60a34dcf6c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;ridge&#x27;, Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5d424a7e-c342-42b7-963e-7b22682e95d2\" type=\"checkbox\" ><label for=\"5d424a7e-c342-42b7-963e-7b22682e95d2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a4f9bab0-b0e4-4844-9043-95f66bd23581\" type=\"checkbox\" ><label for=\"a4f9bab0-b0e4-4844-9043-95f66bd23581\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('ridge', Ridge())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "ridge_param_dict = ''\n",
    "ridge_pipe = ''\n",
    "ridge_grid = ''\n",
    "ridge_train_mse = ''\n",
    "ridge_test_mse = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ridge_param_dict = {'ridge__alpha': np.logspace(0, 10, 50)}\n",
    "ridge_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                      ('ridge', Ridge())])\n",
    "ridge_grid = GridSearchCV(ridge_pipe, param_grid=ridge_param_dict)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "ridge_train_preds = ridge_grid.predict(X_train)\n",
    "ridge_test_preds = ridge_grid.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_train_preds)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_test_preds)\n",
    "### END SOLUTION\n",
    "\n",
    "# ANSWER CHECK\n",
    "print(f'Train MSE: {ridge_train_mse}')\n",
    "print(f'Test MSE: {ridge_test_mse}')\n",
    "ridge_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd8d23006d29b981",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ridge_param_dict_ = {'ridge__alpha': np.logspace(0, 10, 50)}\n",
    "ridge_pipe_ = Pipeline([('scaler', StandardScaler()), \n",
    "                      ('ridge', Ridge())])\n",
    "ridge_grid_ = GridSearchCV(ridge_pipe_, param_grid=ridge_param_dict_)\n",
    "ridge_grid_.fit(X_train, y_train)\n",
    "ridge_train_preds_ = ridge_grid_.predict(X_train)\n",
    "ridge_test_preds_ = ridge_grid_.predict(X_test)\n",
    "ridge_train_mse_ = mean_squared_error(y_train, ridge_train_preds_)\n",
    "ridge_test_mse_ = mean_squared_error(y_test, ridge_test_preds_)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(ridge_param_dict_['ridge__alpha'], ridge_param_dict['ridge__alpha'])\n",
    "assert ridge_train_mse == ridge_train_mse_\n",
    "assert ridge_test_mse == ridge_test_mse_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc0d54dcdc797fd0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Examining the \"best\" model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Your results should suggest that the model using the sequential feature selector and `LinearRegression` estimator.  This was fit with the object `selector_grid`.  One question we may have is what was the optimal number of features selected and what were they?  \n",
    "\n",
    "Use the `selector_grid` to extract both the feature names and their associated coefficients.  This will involve:\n",
    "\n",
    "- `.best_estimator_`: extract the best estimator/selector pair from your grid search\n",
    "- `.named_steps['selector']`: extract the selector from the pipeline\n",
    "- `.named_steps['model']`: extract the model from the pipeline\n",
    "- `.get_support()`: extract best features from selector.  This returns booleans as to whether feature was selected, we can use this to slice our train data.  \n",
    "\n",
    "```python\n",
    "X_train.columns[best_selector.get_support()]\n",
    "```\n",
    "\n",
    "- `.coef_`: coefficients from best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-086dc1fb9b5bad93",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('selector',\n",
      "                 SequentialFeatureSelector(estimator=LinearRegression(),\n",
      "                                           n_features_to_select=2)),\n",
      "                ('model', LinearRegression())])\n",
      "Features from best selector: Index(['age', 'bmi children'], dtype='object').\n",
      "Coefficient values: \n",
      "===================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.032852</td>\n",
       "      <td>0.00368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  bmi children\n",
       "model  0.032852       0.00368"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "best_estimator = ''\n",
    "best_selector = ''\n",
    "best_model = ''\n",
    "feature_names = ''\n",
    "coefs = ''\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "best_estimator = selector_grid.best_estimator_\n",
    "best_selector = best_estimator.named_steps['selector']\n",
    "best_model = selector_grid.best_estimator_.named_steps['model']\n",
    "feature_names = X_train.columns[best_selector.get_support()]\n",
    "coefs = best_model.coef_\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(best_estimator)\n",
    "print(f'Features from best selector: {feature_names}.')\n",
    "print('Coefficient values: ')\n",
    "print('===================')\n",
    "pd.DataFrame([coefs.T], columns = feature_names, index = ['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-727135aa3ceb8535",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "best_estimator_ = selector_grid_.best_estimator_\n",
    "best_selector_ = best_estimator_.named_steps['selector']\n",
    "best_model_ = selector_grid_.best_estimator_.named_steps['model']\n",
    "feature_names_ = X_train.columns[best_selector_.get_support()]\n",
    "coefs_ = best_model_.coef_\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(coefs, coefs_)\n",
    "np.testing.assert_array_equal(feature_names, feature_names_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b828dc090256f1c7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 4\n",
    "\n",
    "#### Comparing observations \n",
    "\n",
    "**10 Points**\n",
    "\n",
    "According to your model, predict the billed costs for person 1 and person 2 below:\n",
    "\n",
    "- **Person 1**: Age = 30, bmi = 40, children = 0\n",
    "- **Person 2**: Age = 45, bmi = 50, children = 2\n",
    "\n",
    "Use the information from **Problem 3** and the model coefficients to make these predictions.\n",
    "\n",
    "Note that you will want to transform your predictions.  From your model the predictions are in terms of the logarithm of cost.  To transform the logarithm to the actual value, use `np.exp` -- the inverse of a logarithm. Assign your predictions as floats to `person1` and `person2` below.  Your solution will be checked to two decimal point accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-51bce4efc95aa858",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between Person 1 and Person 2 is  8052.04\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ages = [30, 45]\n",
    "bmis = [40, 50]\n",
    "childrens = [0, 2]\n",
    "person1 = ''\n",
    "person2 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "person1 = np.exp(best_model.intercept_ + coefs[0]*ages[0] + coefs[1]*(bmis[0]*childrens[0]))\n",
    "person2 = np.exp(best_model.intercept_ + coefs[0]*ages[1] + coefs[1]*(bmis[1]*childrens[1]))\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(f'The difference between Person 1 and Person 2 is {person2 - person1: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5bb5e273c425e0a8",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ages = [30, 45]\n",
    "bmis = [40, 50]\n",
    "childrens = [0, 2]\n",
    "person1_ = np.exp(best_model.intercept_ + coefs[0]*ages[0] + coefs[1]*(bmis[0]*childrens[0]))\n",
    "person2_ = np.exp(best_model.intercept_ + coefs[0]*ages[1] + coefs[1]*(bmis[1]*childrens[1]))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert round(float(person1), 2) == round(float(person1_), 2), 'Person 1 is not correct.'\n",
    "assert round(float(person2), 2) == round(float(person2_), 2), 'Person 2 is not correct.'\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d53afcbf13ed189",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The models here could be revisited and more encoding of features and different polynomial terms can be incorporated.  More important is understanding how to construct the pipelines and interrogate the resulting models to understand what they say about your data.  Does having a higher body mass matter if one does not have children?  Does this seem reasonable?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
