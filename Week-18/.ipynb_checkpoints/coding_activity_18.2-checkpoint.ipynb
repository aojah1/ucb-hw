{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2dab136f3f285526",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 18.2: Named Entities\n",
    "\n",
    "**Expected Time = 45 minutes**\n",
    "\n",
    "**Total Points = 30**\n",
    "\n",
    "This activity focuses on extracting named entities from text.  The named entities will be extracted using the `nltk` library.  You will read in the full text of Newton's *Principia* and identify the entities labeled as places.  \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)\n",
    "- [Problem 6](#-Problem-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/codio/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/codio/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/codio/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/codio/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6875bd64c2ef903",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Opening a `.txt` file.\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Use the `open` function to open the text file with the Principia by Isaac Newton using the filepath given below.  Assign the text using the `readlines()` function to assign the text as a list of lines to the variable `principia` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/Philosophiae_Naturalis_Principia_Mathematica.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9aba37c2556f6459",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "with open(filepath) as f:\n",
    "    principia = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "with open(filepath) as f:\n",
    "    principia = f.readlines()\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(principia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c24bf604efe53156",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "with open(filepath) as f:\n",
    "    principia_ = f.readlines()\n",
    "#\n",
    "#\n",
    "#\n",
    "assert principia == principia_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a0835a4a22385e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Tokenizing the text. \n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Using the `principia` variable from problem 1, combine the `' '.join()` function with `word_tokenize` to create a list of tokens named `tokens` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-807f689ba0e006c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Philosophiae', 'Naturalis', 'Principia', 'Mathematica', 'Isaacus']\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "tokens = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tokens = word_tokenize(' '.join(principia))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(tokens))\n",
    "print(tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-27ceb37df417dbbc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "with open(filepath) as f:\n",
    "    principia_ = f.readlines()\n",
    "    \n",
    "tokens_ = word_tokenize(' '.join(principia_))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert tokens == tokens_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7dcdb426f4e87995",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Part of Speech Tags \n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Use the `pos_tag` function to create the part of speech tagged corpus of the principia text.  Assign the tagged text to the variable `words_pos` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-650ad3c54397b85a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[('Philosophiae', 'NNP'), ('Naturalis', 'NNP'), ('Principia', 'NNP'), ('Mathematica', 'NNP'), ('Isaacus', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "words_pos = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "words_pos = nltk.pos_tag(tokens)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(words_pos))\n",
    "print(words_pos[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c07997113ae412c8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "with open(filepath) as f:\n",
    "    principia_ = f.readlines()\n",
    "    \n",
    "tokens_ = word_tokenize(' '.join(principia_))\n",
    "words_pos_ = nltk.pos_tag(tokens_)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert words_pos == words_pos_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee0e86460f002861",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Named Entities\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Use the tagged words in `words_pos` to create a list of tuples in the form (word, entity type) if the word has a named entity label.  Assign these tuples to the list `named_entities` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce072603df835fbd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[('Philosophiae', 'GSP'), ('Naturalis Principia Mathematica Isaacus Newtonus', 'PERSON'), ('Wikisource', 'GPE'), ('INDEX Tituli', 'ORGANIZATION'), ('Auctoris', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "named_entities = []\n",
    "\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "named_entities = []\n",
    "for word in nltk.ne_chunk(words_pos):\n",
    "    if hasattr(word, 'label'):\n",
    "        named_entities.append((' '.join(c[0] for c in word.leaves()), word.label()))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(named_entities))\n",
    "print(named_entities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5d52b6005bcf4b3e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "with open(filepath) as f:\n",
    "    principia_ = f.readlines()\n",
    "    \n",
    "tokens_ = word_tokenize(' '.join(principia_))\n",
    "words_pos_ = nltk.pos_tag(tokens_)\n",
    "named_entities_ = []\n",
    "for word in nltk.ne_chunk(words_pos_):\n",
    "    if hasattr(word, 'label'):\n",
    "        named_entities_.append((' '.join(c[0] for c in word.leaves()), word.label()))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert named_entities == named_entities_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-010a845bf5cb4d22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Removing People\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Use the `named_entities` list to include only entities labeled `GPE` and create a list of these words lowercased as `places` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a23882a47b1e5974",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['wikisource', 'auctoris', 'umbilico', 'orbibus', 'orbibus']\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "places = []\n",
    "\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "places = [i[0].lower() for i in named_entities if i[1] == 'GPE']\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(places))\n",
    "print(places[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e74c123002f87e04",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "places_ = [i[0].lower() for i in named_entities_ if i[1] == 'GPE']\n",
    "#\n",
    "#\n",
    "#\n",
    "assert places == places_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7d9df33ade83e4fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Removing stopwords\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Use the list `places` to remove all stopwords.  Assign these words as a list to `no_stops` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f48753c59ed8ad9c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['wikisource', 'auctoris', 'umbilico', 'orbibus', 'orbibus', 'superficiebus', 'mediis', 'fluida']\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "no_stops = ''\n",
    "\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "no_stops = [i for i in places if not i in stopwords.words('english')]\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(type(no_stops))\n",
    "print(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-233a5f1eeb96d37e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "places_ = [i[0].lower() for i in named_entities_ if i[1] == 'GPE']\n",
    "no_stops_ = [i for i in places_ if not i in stopwords.words('english')]\n",
    "#\n",
    "#\n",
    "#\n",
    "assert no_stops == no_stops_\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
