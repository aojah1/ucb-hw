{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Aggregate Models for Regression\n",
    "\n",
    "This try-it focuses on utilizing ensemble models in a regression setting.  Much like you have used individual classification estimators to form an ensemble of estimators -- here your goal is to explore ensembles for regression models.  As with your earlier assignment, you will use scikitlearn to carry out the ensembles using the `VotingRegressor`.   \n",
    "\n",
    "\n",
    "#### Dataset and Task\n",
    "\n",
    "Below, a dataset containing census information on individuals and their hourly wage is loaded using the `fetch_openml` function.  OpenML is another repository for datasets [here](https://www.openml.org/).  Your task is to use ensemble methods to explore predicting the `wage` column of the data.  Your ensemble should at the very least consider the following models:\n",
    "\n",
    "- `LinearRegression` -- perhaps you even want the `TransformedTargetRegressor` here.\n",
    "- `KNeighborsRegressor`\n",
    "- `DecisionTreeRegressor`\n",
    "- `Ridge`\n",
    "- `SVR`\n",
    "\n",
    "Tune the `VotingRegressor` to try to optimize the prediction performance and determine if the wisdom of the crowd performed better in this setting than any of the individual models themselves.  Report back on your findings and discuss the interpretability of your findings.  Is there a way to determine what features mattered in predicting wages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n"
     ]
    }
   ],
   "source": [
    "data = fetch_openml(data_id=534, as_frame=True).frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>SOUTH</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "      <th>UNION</th>\n",
       "      <th>WAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>RACE</th>\n",
       "      <th>OCCUPATION</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>MARR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>no</td>\n",
       "      <td>female</td>\n",
       "      <td>21</td>\n",
       "      <td>not_member</td>\n",
       "      <td>5.10</td>\n",
       "      <td>35</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Other</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>no</td>\n",
       "      <td>female</td>\n",
       "      <td>42</td>\n",
       "      <td>not_member</td>\n",
       "      <td>4.95</td>\n",
       "      <td>57</td>\n",
       "      <td>White</td>\n",
       "      <td>Other</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>not_member</td>\n",
       "      <td>6.67</td>\n",
       "      <td>19</td>\n",
       "      <td>White</td>\n",
       "      <td>Other</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Unmarried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>4</td>\n",
       "      <td>not_member</td>\n",
       "      <td>4.00</td>\n",
       "      <td>22</td>\n",
       "      <td>White</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Unmarried</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>not_member</td>\n",
       "      <td>7.50</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Married</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDUCATION SOUTH     SEX  EXPERIENCE       UNION  WAGE  AGE      RACE  \\\n",
       "0          8    no  female          21  not_member  5.10   35  Hispanic   \n",
       "1          9    no  female          42  not_member  4.95   57     White   \n",
       "2         12    no    male           1  not_member  6.67   19     White   \n",
       "3         12    no    male           4  not_member  4.00   22     White   \n",
       "4         12    no    male          17  not_member  7.50   35     White   \n",
       "\n",
       "  OCCUPATION         SECTOR       MARR  \n",
       "0      Other  Manufacturing    Married  \n",
       "1      Other  Manufacturing    Married  \n",
       "2      Other  Manufacturing  Unmarried  \n",
       "3      Other          Other  Unmarried  \n",
       "4      Other          Other    Married  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict Wage\n",
    "X = data.drop(columns=['WAGE'])\n",
    "y = data['WAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorical and numerical feature split\n",
    "categorical_features = ['SOUTH', 'SEX', 'UNION', 'RACE', 'OCCUPATION', 'SECTOR', 'MARR']\n",
    "numerical_features = ['EDUCATION', 'EXPERIENCE', 'AGE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for categorical (one-hot) and numeric (scaling) features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model pipelines\n",
    "models = {\n",
    "    'LinearRegression': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
    "    'Ridge': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', Ridge())]),\n",
    "    'KNeighborsRegressor': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', KNeighborsRegressor())]),\n",
    "    'DecisionTreeRegressor': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', DecisionTreeRegressor())]),\n",
    "    'SVR': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', SVR())])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: MSE = 19.502597324112376, R^2 = 0.3882212186709215\n",
      "Ridge: MSE = 19.504597676303987, R^2 = 0.3881584694377974\n",
      "KNeighborsRegressor: MSE = 19.771630616822435, R^2 = 0.3797818884004033\n",
      "DecisionTreeRegressor: MSE = 49.28300490654206, R^2 = -0.5459631443388546\n",
      "SVR: MSE = 20.983530209733768, R^2 = 0.3417656978529092\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate individual models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'{name}: MSE = {mean_squared_error(y_test, y_pred)}, R^2 = {r2_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.236535301774214\n",
      "R^2: 0.33382915769334875\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing\n",
    "categorical_features = ['SOUTH', 'SEX', 'UNION', 'RACE', 'OCCUPATION', 'SECTOR', 'MARR']\n",
    "numeric_features = ['EDUCATION', 'EXPERIENCE', 'AGE']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)])\n",
    "\n",
    "# Models\n",
    "models = [\n",
    "    ('lr', LinearRegression()),\n",
    "    ('knn', KNeighborsRegressor()),\n",
    "    ('tree', DecisionTreeRegressor()),\n",
    "    ('ridge', Ridge()),\n",
    "    ('svr', SVR())\n",
    "]\n",
    "# Voting regressor with equal weights for simplicity\n",
    "voting_regressor = VotingRegressor(estimators=models)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('voting_regressor', voting_regressor)])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'R^2: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation Importance Scores:\n",
      "EDUCATION: 0.334338738425728\n",
      "SOUTH: -0.0005318648708762419\n",
      "SEX: 0.07163808869393483\n",
      "EXPERIENCE: 0.021027444150094464\n",
      "UNION: 0.003359527041061572\n",
      "AGE: 0.023951297010808413\n",
      "RACE: 0.003951351387968982\n",
      "OCCUPATION: 0.09332833780412698\n",
      "SECTOR: 0.004527812316646162\n",
      "MARR: -0.004540294897846764\n"
     ]
    }
   ],
   "source": [
    "# Permutation Importance\n",
    "result = permutation_importance(pipeline, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importance_scores = result.importances_mean\n",
    "\n",
    "# Report feature importance\n",
    "print(\"Permutation Importance Scores:\")\n",
    "for feature, score in zip(X.columns, importance_scores):\n",
    "    print(f\"{feature}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weights: [2, 1, 1, 1, 1]\n",
      "Tuned VotingRegressor: MSE = 20.884409156820546, R^2 = 0.3448750353399902\n"
     ]
    }
   ],
   "source": [
    "# Tuning Voting Regressor (ensemble)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the base models with pipelines\n",
    "models = {\n",
    "    'lr': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', LinearRegression())]),\n",
    "    'ridge': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', Ridge())]),\n",
    "    'knn': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', KNeighborsRegressor())]),\n",
    "    'tree': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', DecisionTreeRegressor())]),\n",
    "    'svr': Pipeline(steps=[('preprocessor', preprocessor), ('regressor', SVR())])\n",
    "}\n",
    "\n",
    "\n",
    "# Create the Voting Regressor without weights (initial version)\n",
    "voting_regressor = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('lr', models['lr']),\n",
    "        ('ridge', models['ridge']),\n",
    "        ('knn', models['knn']),\n",
    "        ('tree', models['tree']),\n",
    "        ('svr', models['svr'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define weight combinations to search over\n",
    "param_grid = {\n",
    "    'weights': [\n",
    "        [1, 1, 1, 1, 1],   # Equal weights\n",
    "        [1, 2, 1, 1, 1],   # More weight to Ridge\n",
    "        [2, 1, 1, 1, 1],   # More weight to Linear Regression\n",
    "        [1, 1, 2, 1, 1],   # More weight to KNN\n",
    "        [1, 1, 1, 2, 1],   # More weight to Decision Tree\n",
    "        [1, 1, 1, 1, 2],   # More weight to SVR\n",
    "        [0.5, 2, 0.5, 1, 2], # Different combination of weights\n",
    "        # Add more combinations as needed\n",
    "    ]\n",
    "}\n",
    "\n",
    "# GridSearchCV to find the best weights\n",
    "grid_search = GridSearchCV(voting_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator and weights\n",
    "best_voting_regressor = grid_search.best_estimator_\n",
    "best_weights = grid_search.best_params_['weights']\n",
    "\n",
    "# Predict using the tuned Voting Regressor\n",
    "y_pred_tuned = best_voting_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
    "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(f'Best Weights: {best_weights}')\n",
    "print(f'Tuned VotingRegressor: MSE = {mse_tuned}, R^2 = {r2_tuned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 23 features, but ColumnTransformer is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate Permutation Importance\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m perm_importance \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_voting_regressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Display Permutation Importance\u001b[39;00m\n\u001b[1;32m     10\u001b[0m importances \u001b[38;5;241m=\u001b[39m perm_importance\u001b[38;5;241m.\u001b[39mimportances_mean\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/inspection/_permutation_importance.py:287\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    284\u001b[0m     scorers_dict \u001b[38;5;241m=\u001b[39m _check_multimetric_scoring(estimator, scoring)\n\u001b[1;32m    285\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m _MultimetricScorer(scorers\u001b[38;5;241m=\u001b[39mscorers_dict)\n\u001b[0;32m--> 287\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m \u001b[43m_weights_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m scores \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(\n\u001b[1;32m    290\u001b[0m     delayed(_calculate_permutation_scores)(\n\u001b[1;32m    291\u001b[0m         estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    302\u001b[0m )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/inspection/_permutation_importance.py:25\u001b[0m, in \u001b[0;36m_weights_scorer\u001b[0;34m(scorer, estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(estimator, X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:527\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/base.py:760\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \n\u001b[1;32m    720\u001b[0m \u001b[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m--> 760\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/ensemble/_voting.py:624\u001b[0m, in \u001b[0;36mVotingRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03mThe predicted regression target of an input sample is computed as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m    The predicted values.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39maverage(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights_not_none)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/ensemble/_voting.py:68\u001b[0m, in \u001b[0;36m_BaseVoting._predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray([est\u001b[38;5;241m.\u001b[39mpredict(X) \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_])\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/ensemble/_voting.py:68\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray([\u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_])\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/pipeline.py:514\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    512\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 514\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:825\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(\n\u001b[1;32m    828\u001b[0m     X,\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    832\u001b[0m     column_as_strings\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m    833\u001b[0m )\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 23 features, but ColumnTransformer is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Calculate Permutation Importance\n",
    "perm_importance = permutation_importance(best_voting_regressor, X_test_transformed, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# Display Permutation Importance\n",
    "importances = perm_importance.importances_mean\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
