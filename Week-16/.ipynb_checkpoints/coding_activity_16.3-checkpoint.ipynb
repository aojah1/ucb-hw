{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e2e75e5d7897be3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 16.3: Fitting Models with Kernel Functions\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 35**\n",
    "\n",
    "This assignment focuses on using kernel functions like those shown in the lectures and comparing the resulting decision boundaries.  You will again use the wine data, first by applying a polynomial kernel function to the data and then fitting a `LogisticRegression` estimator on the transformed data.  Using a similar approach to the last assignment, you will visualize the decision boundaries that result from the kernel functions.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eddc27687ef91fd7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### The Data\n",
    "\n",
    "The wine data is loaded, subset to `total_phenols` and `color_intensity`, and split into train/test sets below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_wine(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[['total_phenols', 'color_intensity']].values, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b79fa55c23dfee00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Logistic Regression with Linear Kernel\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, you are provided two functions -- `Kernel_matrix` and `evaluate_kernel_model` -- that are taken from the lectures.  Use these functions together with the function `linear_kernel` to determine the following variables:\n",
    "\n",
    "```\n",
    "- linear_kernel_matrix: Create Kernel Matrix using linear_kernel_function and X_train\n",
    "- linear_logistic: Fit a LogisticRegression model (using max_iter=1000) on the Kernel Matrix and y_train\n",
    "- linear_predictions: Evaluate the model using evaluate_kernel_model and X_train, X_test\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel_matrix(kfunc, X):\n",
    "    N, _ = X.shape\n",
    "    K = np.empty((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i, j] = kfunc(X[i, :], X[j, :])\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kernel_model(model, kfunc, X_train, X_test):\n",
    "    N1, _ = X_train.shape\n",
    "    N2, _ = X_test.shape\n",
    "    \n",
    "    K = np.empty((N2, N1))\n",
    "    for i in range(N2):\n",
    "        for j in range(N1):\n",
    "            K[i, j] = kfunc(X_train[j, :], X_test[i, :])\n",
    "    return model.predict(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel_function(x, z):\n",
    "    return np.dot(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0435c5826922e290",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 0 0 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "linear_kernel_matrix = ''\n",
    "linear_logistic = ''\n",
    "linear_predictions = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "linear_kernel_matrix = Kernel_matrix(linear_kernel_function, X_train)\n",
    "\n",
    "linear_logistic = LogisticRegression(max_iter=1000).fit(linear_kernel_matrix, y_train)\n",
    "\n",
    "linear_predictions = evaluate_kernel_model(linear_logistic, linear_kernel_function, X_train, X_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(linear_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to Visualize\n",
    "# xx = np.linspace(X_train[:, 0].min(), X_train[:, 0].max(), 50)\n",
    "# yy = np.linspace(X_train[:, 1].min(), X_train[:, 1].max(), 50)\n",
    "# XX, YY = np.meshgrid(xx, yy)\n",
    "\n",
    "# grid = np.c_[XX.ravel(), YY.ravel()]\n",
    "# labels = evaluate_kernel_model(linear_logistic, linear_kernel_function, X_train, grid)\n",
    "\n",
    "# plt.contourf(xx, yy, labels.reshape(XX.shape), cmap = 'tab10', alpha = 0.3)\n",
    "# sns.scatterplot(data = X, x = 'total_phenols', y = 'color_intensity', hue = y)\n",
    "# plt.xlim(1, 3.5)\n",
    "# plt.ylim(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5845e8a9d8bc1210",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "linear_kernel_matrix_ = Kernel_matrix(linear_kernel_function, X_train)\n",
    "\n",
    "linear_logistic_ = LogisticRegression(max_iter=1000).fit(linear_kernel_matrix_, y_train)\n",
    "\n",
    "linear_predictions_ = evaluate_kernel_model(linear_logistic_, linear_kernel_function, X_train, X_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(linear_predictions, linear_predictions_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c88d4e9a18b71f3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Logistic Regression with Quadratic Kernel\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, complete the `quadratic_kernel_function` below to implement a polynomial kernel of degree 2 on the input data similar to that of the `linear_kernel_function`.  Then, use the quadratic kernel to generate a `quadratic_kernel_matrix` object, and fit a logistic model as `quadratic_logistic` below -- to avoid a convergence warning set `max_iter = 1000`.  Make predictions as `quadratic_predictions` and uncomment the code to visualize the resulting decision boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7cee5fc783c43997",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 0 0 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "def quadratic_kernel_function(x, z):\n",
    "    '''\n",
    "    This function applies a quadratic kernel to \n",
    "    array x and z.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "quadratic_kernel_matrix = ''\n",
    "quadratic_logistic = ''\n",
    "quadratic_predictions = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def quadratic_kernel_function(x, z):\n",
    "    return (np.dot(x, z) + 1) ** 2\n",
    "quadratic_kernel_matrix = Kernel_matrix(quadratic_kernel_function, X_train)\n",
    "\n",
    "quadratic_logistic = LogisticRegression(max_iter=1000).fit(quadratic_kernel_matrix, y_train)\n",
    "\n",
    "quadratic_predictions = evaluate_kernel_model(quadratic_logistic, quadratic_kernel_function, X_train, X_test)### END SOLUTION\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(quadratic_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = evaluate_kernel_model(quadratic_logistic, quadratic_kernel_function, X_train, grid)\n",
    "\n",
    "# plt.contourf(xx, yy, labels.reshape(XX.shape), cmap = 'tab10', alpha = 0.3)\n",
    "# sns.scatterplot(data = X, x = 'total_phenols', y = 'color_intensity', hue = y)\n",
    "# plt.xlim(1, 3.5)\n",
    "# plt.ylim(2, 10)\n",
    "# plt.title('Quadratic Decision Boundary with Kernel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-74b3f1b99b325856",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "def quadratic_kernel_function_(x, z):\n",
    "    return (np.dot(x, z) + 1) ** 2\n",
    "quadratic_kernel_matrix_ = Kernel_matrix(quadratic_kernel_function_, X_train)\n",
    "\n",
    "quadratic_logistic_ = LogisticRegression(max_iter=1000).fit(quadratic_kernel_matrix_, y_train)\n",
    "\n",
    "quadratic_predictions_ = evaluate_kernel_model(quadratic_logistic_, quadratic_kernel_function_, X_train, X_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(quadratic_predictions, quadratic_predictions_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a172c88c1b43837",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Logistic Regression with Quintic Kernel\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Finally, complete the function `quintic_kernel_function` below that creates a polynomial kernel of degree 5.  Use this to create the `quintic_kernel_matrix`, `quintic_logistic`, and `quintic_predictions`.  \n",
    "\n",
    "**NOTE**: To avoid convergence warnings here, set the `max_iter = 10_000` in your `quintic_logistic` estimator.\n",
    "\n",
    "Uncomment the code to visualize the new decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f8664952a032c134",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 1 0 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "def quintic_kernel_function(x, z):\n",
    "    '''\n",
    "    This function applies a quintic (5th degree\n",
    "    polynomial) kernel to \n",
    "    array x and z.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "quintic_kernel_matrix = ''\n",
    "quintic_logistic = ''\n",
    "quintic_predictions = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def quintic_kernel_function(x, z):\n",
    "    return (np.dot(x, z) + 1) ** 5\n",
    "quintic_kernel_matrix = Kernel_matrix(quintic_kernel_function, X_train)\n",
    "\n",
    "quintic_logistic = LogisticRegression(max_iter=10000).fit(quintic_kernel_matrix, y_train)\n",
    "\n",
    "quintic_predictions = evaluate_kernel_model(quintic_logistic, quintic_kernel_function, X_train, X_test)### END SOLUTION\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(quintic_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = evaluate_kernel_model(quintic_logistic, quintic_kernel_function, X_train, grid)\n",
    "# plt.contourf(xx, yy, labels.reshape(XX.shape), cmap = 'tab10', alpha = 0.3)\n",
    "# sns.scatterplot(data = X, x = 'total_phenols', y = 'color_intensity', hue = y)\n",
    "# plt.xlim(1, 3.5)\n",
    "# plt.ylim(2, 10)\n",
    "# plt.title('Decision Boundary with Polynomial Degree 5 (Quintic) Kernel');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ba8ddc87e509bef6",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "def quintic_kernel_function_(x, z):\n",
    "    return (np.dot(x, z) + 1) ** 5\n",
    "quintic_kernel_matrix_ = Kernel_matrix(quintic_kernel_function_, X_train)\n",
    "\n",
    "quintic_logistic_ = LogisticRegression(max_iter=10000).fit(quintic_kernel_matrix_, y_train)\n",
    "\n",
    "quintic_predictions_ = evaluate_kernel_model(quintic_logistic_, quintic_kernel_function_, X_train, X_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(quintic_predictions, quintic_predictions_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7d82ff8dd223a07",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Evaluate the Models\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Of the three models, which performed the best on the test data in terms of overall accuracy?  Assign your answer as a string to `best_acc` below -- `linear`, `quadratic`, or `quintic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e164450b510cff7c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "best_acc = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "best_acc = 'linear'\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2c2b1c55873ce6a0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "best_acc_ = 'linear'\n",
    "#\n",
    "#\n",
    "#\n",
    "assert best_acc == best_acc_\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
